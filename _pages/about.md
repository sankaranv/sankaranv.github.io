---
layout: about
title: About
permalink: /
subtitle: <em>shun-ka-run</em>&nbsp;&nbsp;&nbsp;&nbsp;&#x2022;&nbsp;&nbsp;&nbsp;&nbsp;/ʃʌŋkəˈɹʌn/&nbsp;&nbsp;&nbsp;&nbsp;&#x2022;&nbsp;&nbsp;&nbsp;&nbsp;<span class='tamil'>சங்கரன்</span>
profile:
  align: right
  image: me.jpg
  image_circular: true # crops the image to make it circular
  # more_info: >
  #   <div style="text-align: center;">
  #     <p>sankaran@cs.umass.edu</p>
  #   </div>
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

# latest_posts:
#   enabled: true
#   scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
#   limit: 3 # leave blank to include all the blog posts
---

I am a PhD candidate at the [College of Information and Computer Sciences, UMass Amherst](https://www.cics.umass.edu/), where I am advised by [David Jensen](https://people.cs.umass.edu/~jensen/). My research focuses on developing principled tools grounded in *causal reasoning* for explaining and evaluating complex AI systems, including large language models (LLMs) and reinforcement learning agents. 

In particular, I focus on problems where *subjective human judgments* play a central role, including mechanistic interpretability in neural networks, evaluating LLM outputs, blame and responsibility attribution, and alignment with human social norms. These domains are often difficult to model using conventional statistical approaches in causality and machine learning: human judgments are shaped by implicit expectations, context-sensitive reasoning, and the tendency to highlight some causes over others based on agreed-upon social norms. 

By developing methods grounded in scientific rigor and the human values that guide real-world decision-making, I aim to enable *reliable evaluation* and *responsible governance* of AI systems.