<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    Sankaran Vaidyanathan
  
</title>
<meta name="author" content="Sankaran Vaidyanathan">
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">



<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;500;600;700&amp;family=Inter:wght@400;500;700&amp;family=IBM+Plex+Sans:wght@400;600&amp;family=Baloo+Thambi+2&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->




  <link rel="shortcut icon" href="/assets/img/favicon.ico?d18a0e2a2d4a6df7c6cb9b8271b63824">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="http://0.0.0.0:8080/">

<!-- Dark Mode -->
<script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script>

  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>










  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                <li class="nav-item ">
                  <a class="nav-link" href="/blog/">blog
                    
                  </a>
                </li>
              
            
          
            
              
                
                <li class="nav-item ">
                  <a class="nav-link" href="/publications/">publications
                    
                  </a>
                </li>
              
            
          
            
              
                
                <li class="nav-item ">
                  <a class="nav-link" href="/cv/">cv
                    
                  </a>
                </li>
              
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        <div class="post">
  <header class="post-header">
    <h1 class="post-title">
      
        <span class="font-weight-bold">Sankaran</span> 
        Vaidyanathan
      
    </h1>
    <p class="desc"><em>shun-ka-run</em>  •  /ʃʌŋkəˈɹʌn/  •  <span class="tamil">சங்கரன்</span></p>
  </header>

  <article>
    
      <div class="profile float-right">
        
          
          
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/me-480.webp 480w,/assets/img/me-800.webp 800w,/assets/img/me-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px)
      30vw, 95vw">
      
    
    <img src="/assets/img/me.jpg?685f833ea2a2a2bcb073cfec520e4f99" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="me.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </source></picture>

  
</figure>

        
        
      </div>
    

    <div class="clearfix">
<p>I am a PhD student at the <a href="https://www.cics.umass.edu/" rel="external nofollow noopener" target="_blank">College of Information and Computer Sciences, UMass Amherst</a>, where I am advised by <a href="https://people.cs.umass.edu/~jensen/" rel="external nofollow noopener" target="_blank">David Jensen</a>. My research spans the areas of causal inference, probabilistic machine learning, and reinforcement learning. More recently, I have also worked on approaches for mechanistic interpretability in LLMs.</p>

<p>I aim to create tools for analyzing and evaluating the behaviour of complex AI systems, with a focus on problems in blame and responsibility attribution, explainability, and alignment with human norms. Unlike most applications of causal inference that involve objective experimentation and interaction with the external world, these issues are traditionally grounded in subjective human judgments. These involve <b>norms</b> that can be very counterintuitive, and pose a significant challenge to purely statistical approaches in causal inference. By developing formal approaches for modeling norms and inference algorithms that align with norms, I hope to support open and scientific evaluation and auditing of AI systems, and the growth of AI systems that better align with norms.</p>
</div>

    <!-- News -->
    

    <!-- Latest posts -->
    

    <!-- Selected papers -->
    
      <h2>
        <a href="/publications/" style="color: inherit">selected publications</a>
      </h2>
      <div class="publications">
  <ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">arXiv</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="chuck2024automated" class="col-sm-8">
    <!-- Title -->
    <div class="title">Automated Discovery of Functional Actual Causes in Complex Environments</div>
    <!-- Author -->
    <div class="author">
      

      
      Caleb
            Chuck<sup>*</sup>, <em>Sankaran
            Vaidyanathan<sup>*</sup></em>, Stephen
            Giguere, and
        <span class="more-authors" title="click to view 3 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '3 more authors' ? 'Amy Zhang, David Jensen, Scott Niekum' : '3 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">3 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2404.10883</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
        
          <a href="https://arxiv.org/abs/2404.10883" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://arxiv.org/pdf/2404.10883.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Reinforcement learning (RL) algorithms often struggle to learn policies that generalize to novel situations due to issues such as causal confusion, overfitting to irrelevant factors, and failure to isolate control of state factors. These issues stem from a common source: a failure to accurately identify and exploit state-specific causal relationships in the environment. While some prior works in RL aim to identify these relationships explicitly, they rely on informal domain-specific heuristics such as spatial and temporal proximity. Actual causality offers a principled and general framework for determining the causes of particular events. However, existing definitions of actual cause often attribute causality to a large number of events, even if many of them rarely influence the outcome. Prior work on actual causality proposes normality as a solution to this problem, but its existing implementations are challenging to scale to complex and continuous-valued RL environments. This paper introduces functional actual cause (FAC), a framework that uses context-specific independencies in the environment to restrict the set of actual causes. We additionally introduce Joint Optimization for Actual Cause Inference (JACI), an algorithm that learns from observational data to infer functional actual causes. We demonstrate empirically that FAC agrees with known results on a suite of examples from the actual causality literature, and JACI identifies actual causes with significantly higher accuracy than existing heuristic methods in a set of complex, continuous-valued environments.</p>
      </div>
    

    
      <!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chuck2024automated</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated Discovery of Functional Actual Causes in Complex Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chuck, Caleb and Vaidyanathan, Sankaran and Giguere, Stephen and Zhang, Amy and Jensen, David and Niekum, Scott}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2404.10883}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">arXiv</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="thakur2024judging" class="col-sm-8">
    <!-- Title -->
    <div class="title">Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges</div>
    <!-- Author -->
    <div class="author">
      

      
      Aman Singh
            Thakur<sup>*</sup>, Kartik
            Choudhary<sup>*</sup>, Venkat Srinik
            Ramayapally<sup>*</sup>, and
        <span class="more-authors" title="click to view 2 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '2 more authors' ? 'Sankaran Vaidyanathan, Dieuwke Hupkes' : '2 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">2 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2406.12624</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
        
          <a href="https://arxiv.org/abs/2406.12624" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://arxiv.org/pdf/2406.12624.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Offering a promising solution to the scalability challenges associated with human evaluation, the LLM-as-a-judge paradigm is rapidly gaining traction as an approach to evaluating large language models (LLMs). However, there are still many open questions about the strengths and weaknesses of this paradigm, and what potential biases it may hold. In this paper, we present a comprehensive study of the performance of various LLMs acting as judges, focusing on a clean scenario in which inter-human agreement is high. Investigating thirteen judge models of different model sizes and families, judging answers of nine different ’examtaker models’ - both base and instruction-tuned - we find that only the best (and largest) models achieve reasonable alignment with humans. However, they are still quite far behind inter-human agreement and their assigned scores may still differ with up to 5 points from human-assigned scores. In terms of their ranking of the nine exam-taker models, instead, also smaller models and even the lexical metric contains may provide a reasonable signal. Through error analysis and other studies, we identify vulnerabilities in judge models, such as their sensitivity to prompt complexity and length, and a tendency toward leniency. The fact that even the best judges differ from humans in this comparatively simple setup suggest that caution may be wise when using judges in more complex setups. Lastly, our research rediscovers the importance of using alignment metrics beyond simple percent alignment, showing that judges with high percent agreement can still assign vastly different scores. </p>
      </div>
    

    
      <!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">thakur2024judging</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Thakur, Aman Singh and Choudhary, Kartik and Ramayapally, Venkat Srinik and Vaidyanathan, Sankaran and Hupkes, Dieuwke}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2406.12624}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">arXiv</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="nainani2024adaptive" class="col-sm-8">
    <!-- Title -->
    <div class="title">Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability</div>
    <!-- Author -->
    <div class="author">
      

      
      Jatin
            Nainani<sup>*</sup>, <em>Sankaran
            Vaidyanathan<sup>*</sup></em>, AJ
            Yeung, and
        <span class="more-authors" title="click to view 2 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '2 more authors' ? 'Kartik Gupta, David Jensen' : '2 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">2 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2411.16105</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
        
          <a href="https://arxiv.org/abs/2411.16105" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://arxiv.org/pdf/2411.16105.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Mechanistic interpretability aims to understand the inner workings of large neural networks by identifying circuits, or minimal subgraphs within the model that implement algorithms responsible for performing specific tasks. These circuits are typically discovered and analyzed using a narrowly defined prompt format. However, given the abilities of large language models (LLMs) to generalize across various prompt formats for the same task, it remains unclear how well these circuits generalize. For instance, it is unclear whether the models generalization results from reusing the same circuit components, the components behaving differently, or the use of entirely different components. In this paper, we investigate the generality of the indirect object identification (IOI) circuit in GPT-2 small, which is well-studied and believed to implement a simple, interpretable algorithm. We evaluate its performance on prompt variants that challenge the assumptions of this algorithm. Our findings reveal that the circuit generalizes surprisingly well, reusing all of its components and mechanisms while only adding additional input edges. Notably, the circuit generalizes even to prompt variants where the original algorithm should fail; we discover a mechanism that explains this which we term S2 Hacking. Our findings indicate that circuits within LLMs may be more flexible and general than previously recognized, underscoring the importance of studying circuit generalization to better understand the broader capabilities of these models.</p>
      </div>
    

    
      <!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nainani2024adaptive</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nainani, Jatin and Vaidyanathan, Sankaran and Yeung, AJ and Gupta, Kartik and Jensen, David}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2411.16105}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
    

    
  </div>
</div>
</li>
</ol>
</div>

    

    <!-- Social -->
    
      <div class="social">
        <div class="contact-icons">
  
      <a href="mailto:%73%61%6E%6B%61%72%61%6E%76@%63%73.%75%6D%61%73%73.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a>
    

  
      <a href="https://github.com/sankaranv" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a>
    

  
      <a href="https://www.linkedin.com/in/sankaranv8" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a>
    

  
      <a href="https://scholar.google.com/citations?user=DbeHYRcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
    

  
      <a href="https://www.semanticscholar.org/author/65731722" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a>
    

  
      <a href="https://twitter.com/sankaranv8" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a>
    

</div>

        <div class="contact-note"></div>
      </div>
    

    
  </article>
</div>

      
    </div>

    <!-- Footer -->
    


  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      
  © Copyright 2025
  Sankaran
  
  Vaidyanathan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

  
  

    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>


  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script>























  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>






<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script>
<script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>

<!-- Badges -->

  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>



  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script>
  
    <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script>
  









  <!-- Scrolling Progress Bar -->
  <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script>







  <!-- Back to Top -->
  <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>



  <!-- Search -->
  <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script>
  <script src="/assets/js/search-data.js"></script>
  <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script>




  </body>
</html>
